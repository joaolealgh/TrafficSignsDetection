{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "from torchvision import utils, transforms, datasets\n",
    "from torch.utils.data import Subset\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe6d1bad3d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DATASET = False\n",
    "CALCULATE_MEAN_STD = False\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_SIZE = (32, 32)\n",
    "LR = 0.001\n",
    "DATASET_DIR = '../../dataset/GTSRB'\n",
    "EPOCHS = 10 # Load from a config file\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALCULATE_MEAN_STD:\n",
    "    mean, std = calculate_mean_std_custom_dataset()\n",
    "else:\n",
    "    mean = torch.tensor([0.3403, 0.3121, 0.3214])\n",
    "    std = torch.tensor([0.2724, 0.2608, 0.2669])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_transform = transforms.Compose([\n",
    "        ConvertPIL(),\n",
    "        Rescale(IMAGE_SIZE),\n",
    "        RandCrop(32),\n",
    "        RandHorizFlip(0.5),\n",
    "        RandVertFlip(0.5),\n",
    "        # RandomRotation(),\n",
    "        ToTensor(),\n",
    "        CustomNormalize(mean, std)\n",
    "    ])\n",
    "\n",
    "validation_data_transform = transforms.Compose([\n",
    "        ConvertPIL(),\n",
    "        Rescale(IMAGE_SIZE),\n",
    "        ToTensor(),\n",
    "        CustomNormalize(mean, std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39209\n",
      "31367\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TrafficSignsDataset(annotations_file='../../dataset/GTSRB/Train.csv', \n",
    "                                    root_dir=DATASET_DIR,\n",
    "                                    transform=training_data_transform)\n",
    "\n",
    "valid_dataset = TrafficSignsDataset(annotations_file='../../dataset/GTSRB/Train.csv', \n",
    "                                    root_dir=DATASET_DIR,\n",
    "                                    transform=validation_data_transform)\n",
    "\n",
    "total_count = len(train_dataset)\n",
    "train_count = int(0.8 * total_count)\n",
    "print(total_count)\n",
    "print(train_count)\n",
    "indices = np.arange(0, total_count, 1)\n",
    "np.random.seed(SEED)\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[:train_count], indices[train_count:]\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_idx)\n",
    "valid_dataset = Subset(valid_dataset, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_dataset.dataset.transform)\n",
    "#print(valid_dataset.dataset.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=4)\n",
    "\n",
    "validation_dataset_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_DATASET:\n",
    "    plot_gtsrb_dataset_images(train_dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_traffic_dataset = TrafficSignsDataset(annotations_file='../../dataset/GTSRB/Test.csv', \n",
    "                                           root_dir=DATASET_DIR, \n",
    "                                           transform=transforms.Compose([\n",
    "                                            ConvertPIL(),\n",
    "                                            Rescale(IMAGE_SIZE),\n",
    "                                            ToTensor(),\n",
    "                                            CustomNormalize(mean, std)\n",
    "                                        ]))\n",
    "\n",
    "test_dataset_loader = torch.utils.data.DataLoader(test_traffic_dataset,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=4)\n",
    "\n",
    "if PLOT_DATASET:\n",
    "    plot_gtsrb_dataset_images(test_dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.dataset.get_classes())\n",
    "print(num_classes)\n",
    "\n",
    "from model import CustomCNN\n",
    "net = CustomCNN(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=(3, 3), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=(3, 3), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=51200, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=43, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(train_dataset_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs = data['image']\n",
    "        labels = data['label']\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero your gradients for every batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            last_loss = running_loss / 100 # loss per batch\n",
    "            print('batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            # tb_x = epoch_index * len(train_dataset_loader) + i + 1\n",
    "            # tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "batch 100 loss: 3.2754845142364504\n",
      "batch 200 loss: 2.8440004420280456\n",
      "batch 300 loss: 2.5962338495254516\n",
      "batch 400 loss: 2.360012767314911\n",
      "LOSS train 2.360012767314911 validation 1.4524176120758057\n",
      "EPOCH 2:\n",
      "batch 100 loss: 1.8876409494876862\n",
      "batch 200 loss: 1.7719855999946594\n",
      "batch 300 loss: 1.6162879681587219\n",
      "batch 400 loss: 1.4517453336715698\n",
      "LOSS train 1.4517453336715698 validation 0.7004598379135132\n",
      "EPOCH 3:\n",
      "batch 100 loss: 1.263751167654991\n",
      "batch 200 loss: 1.2551086032390595\n",
      "batch 300 loss: 1.2180856788158416\n",
      "batch 400 loss: 1.1707730042934417\n",
      "LOSS train 1.1707730042934417 validation 0.36877191066741943\n",
      "EPOCH 4:\n",
      "batch 100 loss: 1.0561292690038682\n",
      "batch 200 loss: 1.0614786463975907\n",
      "batch 300 loss: 1.0126129388809204\n",
      "batch 400 loss: 0.9778714472055435\n",
      "LOSS train 0.9778714472055435 validation 0.35179707407951355\n",
      "EPOCH 5:\n",
      "batch 100 loss: 0.9720947587490082\n",
      "batch 200 loss: 0.9283735758066177\n",
      "batch 300 loss: 0.8922549027204514\n",
      "batch 400 loss: 0.913644328713417\n",
      "LOSS train 0.913644328713417 validation 0.24818475544452667\n",
      "EPOCH 6:\n",
      "batch 100 loss: 0.8807662832736969\n",
      "batch 200 loss: 0.8483145368099213\n",
      "batch 300 loss: 0.8270879763364792\n",
      "batch 400 loss: 0.8473878678679466\n",
      "LOSS train 0.8473878678679466 validation 0.2327747941017151\n",
      "EPOCH 7:\n",
      "batch 100 loss: 0.8306248199939728\n",
      "batch 200 loss: 0.7772564944624901\n",
      "batch 300 loss: 0.7975161904096604\n",
      "batch 400 loss: 0.7814280927181244\n",
      "LOSS train 0.7814280927181244 validation 0.21426266431808472\n",
      "EPOCH 8:\n",
      "batch 100 loss: 0.764259597659111\n",
      "batch 200 loss: 0.7322625994682312\n",
      "batch 300 loss: 0.7528835964202881\n",
      "batch 400 loss: 0.7774132907390594\n",
      "LOSS train 0.7774132907390594 validation 0.16013795137405396\n",
      "EPOCH 9:\n",
      "batch 100 loss: 0.7560613948106766\n",
      "batch 200 loss: 0.7432933256030083\n",
      "batch 300 loss: 0.7255797013640404\n",
      "batch 400 loss: 0.7102004384994507\n",
      "LOSS train 0.7102004384994507 validation 0.19734503328800201\n",
      "EPOCH 10:\n",
      "batch 100 loss: 0.7465603864192962\n",
      "batch 200 loss: 0.7090938174724579\n",
      "batch 300 loss: 0.7125408673286437\n",
      "batch 400 loss: 0.6899400055408478\n",
      "LOSS train 0.6899400055408478 validation 0.21325157582759857\n"
     ]
    }
   ],
   "source": [
    "best_vloss = 1_000_000.\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    net.train(True)\n",
    "    avg_loss = train_one_epoch()\n",
    "\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for j, val_data in enumerate(validation_dataset_loader):\n",
    "            inputs = val_data['image']\n",
    "            labels = val_data['label']\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            target = net(inputs)\n",
    "            vloss = criterion(target, labels)\n",
    "            running_vloss += vloss\n",
    "    \n",
    "        avg_vloss = running_vloss / (j + 1)\n",
    "        print('LOSS train {} validation {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        # writer.add_scalars('Training vs. Validation Loss',\n",
    "        #                 { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "        #                 epoch_number + 1)\n",
    "        # writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_path = 'customcnn_{}_{}'.format(timestamp, epoch)\n",
    "            torch.save(net.state_dict(), '../models/'+model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 87 %\n"
     ]
    }
   ],
   "source": [
    "# net = Net()\n",
    "# net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_dataset_loader):\n",
    "        inputs = test_data['image']\n",
    "        labels = test_data['label']\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "\n",
    "# correct_pred = {classname: 0 for classname in classes}\n",
    "# total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# # again no gradients needed\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         images, labels = data\n",
    "#         outputs = net(images)\n",
    "#         _, predictions = torch.max(outputs, 1)\n",
    "#         # collect the correct predictions for each class\n",
    "#         for label, prediction in zip(labels, predictions):\n",
    "#             if label == prediction:\n",
    "#                 correct_pred[classes[label]] += 1\n",
    "#             total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# # print accuracy for each class\n",
    "# for classname, correct_count in correct_pred.items():\n",
    "#     accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "#     print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# add more transformations\n",
    "# add dropout\n",
    "# Plot training vs validation loss\n",
    "# Save best model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
